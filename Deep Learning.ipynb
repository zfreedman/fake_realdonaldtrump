{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning\n",
    "This notebook is responsible for implementing a recurrent neural network using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_user = \"\"\n",
    "db_pass = \"\"\n",
    "db_name = \"\"\n",
    "db_host = \"localhost\"\n",
    "with open(\"database_credentials.txt\") as f:\n",
    "    db_user = f.readline().strip()\n",
    "    db_pass = f.readline().strip()\n",
    "    db_name = f.readline().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe-ize tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb as mdb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Great meeting with @Cabinet at the @WhiteHouse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Looking forward to 3:30 P.M. meeting today at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lowest rated Oscars in HISTORY. Problem is, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>JOBS, JOBS, JOBS! #MAGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The U.S. is acting swiftly on Intellectual Pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message\n",
       "0   1  Great meeting with @Cabinet at the @WhiteHouse...\n",
       "1   2  Looking forward to 3:30 P.M. meeting today at ...\n",
       "2   3  Lowest rated Oscars in HISTORY. Problem is, we...\n",
       "3   4                            JOBS, JOBS, JOBS! #MAGA\n",
       "4   5  The U.S. is acting swiftly on Intellectual Pro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    con = mdb.connect(host=db_host, user=db_user, passwd=db_pass, db=db_name)\n",
    "    df = pd.read_sql(\"\"\"SELECT * FROM search_tweets\"\"\", con)\n",
    "finally:\n",
    "    if con:\n",
    "        con.close()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique space-separated character orderings: 12837\n",
      "Tweets: 2889\n",
      "Average sentences per tweet: 2.76081689166\n"
     ]
    }
   ],
   "source": [
    "#All tweets linearly joined together in a list\n",
    "char_list = \" \".join(list(df[\"message\"]))\n",
    "\n",
    "print(\"Unique space-separated character orderings: {}\".format(len({\n",
    "    word: None for word in char_list.split(\" \")})))\n",
    "print(\"Tweets: {}\".format(df.shape[0]))\n",
    "\n",
    "print(\"Average sentences per tweet: {}\".format(\n",
    "    (char_list.count(\".\") + char_list.count(\"?\") + char_list.count(\"!\")) / float(df.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "### Lookup table\n",
    "In order to create a word embedding, the words used in the tweets need to be transformed to IDs. The 2 way mapping from words->IDs and IDs->words is generated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"here's some sample text. hopefully this\\nworks? ok - time to give it a shot!!\"\n",
    "def get_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Gets the lookup tables mapping character orderings to their IDs and vice-versa.\n",
    "    :param text: Text to create lookup tables from\n",
    "    :return: A tuple of mapes (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    #If passed in text as big string, words separated by spaces\n",
    "    if type(text) == str:\n",
    "        #text = text.translate(None, punctuation).split()\n",
    "        text = text.split()\n",
    "    #If passed in text as list (same as string representation but separated by indices)\n",
    "    elif type(text) == list:\n",
    "        #Handle later\n",
    "        None\n",
    "        \n",
    "    #Create mappings\n",
    "    words = [k for (k,v) in Counter(text).items()]\n",
    "    vocab_to_int = {}\n",
    "    int_to_vocab = {}\n",
    "    for i in range(len(words)):\n",
    "        vocab_to_int[words[i]] = i\n",
    "        int_to_vocab[i] = words[i]\n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "#get_lookup_tables(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation tokenizing\n",
    "Spaces split the tweets up word by words. However, punctuations make it difficult for neural networks to distinguish between \"dream\" and \"dream!\". The requring tokenization mechanism to map characters to their IDs is performed below.\n",
    "\n",
    "With this mapping mechanism, the dictionary will be used to toeknize the symbols and add a space around the character, making the character it's own word. When punctuations act as their own word, the neural network can more easily incorporate them into it's produced language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': '~NEWLINE~',\n",
       " '!': '~EXCLAMATION~',\n",
       " '\"': '~QUOTATION~',\n",
       " '(': '~LEFTPAREN~',\n",
       " ')': '~RIGHTPAREN~',\n",
       " ',': '~COMMA~',\n",
       " '-': '~HYPHEN~',\n",
       " '.': '~PERIOD~',\n",
       " ';': '~SEMICOLON~',\n",
       " '?': '~QUESTION~',\n",
       " '|': '~PIPE~'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Consider adding possessive/abbreviation for punctuation ... \"'\"\n",
    "rnn_punctuation = [\".\", \",\", \"\\\"\", \";\", \"!\", \"?\", \"(\", \")\", \"-\", \"\\n\", \"|\"]\n",
    "rnn_punctuation_words = map(lambda s : \"~\" + s.upper() + \"~\", [\"period\", \"comma\", \"quotation\", \"semicolon\", \"exclamation\",\n",
    "                         \"question\", \"leftparen\", \"rightparen\", \"hyphen\", \"newline\", \"pipe\"])\n",
    "\n",
    "rnn_punctuation_map = {rnn_punctuation[i]: rnn_punctuation_words[i] for i in range(len(rnn_punctuation))}\n",
    "rnn_punctuation_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
